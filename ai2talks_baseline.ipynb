{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing and Downloading","metadata":{"id":"O0asRUp9CYLj"}},{"cell_type":"code","source":"# !apt update\n# !apt -y install ffmpeg\n# !apt install espeak -y\n!pip install wandb\n!pip install transformers datasets phonemizer\n!pip install pydub\n#!pip install transformers --upgrade\n#!pip install torchaudio\n!pip install tqdm --upgrade\n#!pip install torchaudio --upgrade\n!pip install gdown\n!pip install abydos","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2k7fJmkOB-V","outputId":"4587aaac-2adc-460d-9c2f-8a6700918049","execution":{"iopub.status.busy":"2022-10-18T11:30:23.854298Z","iopub.execute_input":"2022-10-18T11:30:23.854740Z","iopub.status.idle":"2022-10-18T11:31:30.566837Z","shell.execute_reply.started":"2022-10-18T11:30:23.854656Z","shell.execute_reply":"2022-10-18T11:31:30.565558Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nCollecting phonemizer\n  Downloading phonemizer-3.2.1-py3-none-any.whl (90 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nCollecting segments\n  Downloading segments-2.2.1-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: attrs>=18.1 in /opt/conda/lib/python3.7/site-packages (from phonemizer) (21.4.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from phonemizer) (1.0.1)\nCollecting dlinfo\n  Downloading dlinfo-1.2.1-py3-none-any.whl (3.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from phonemizer) (4.3.0)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nCollecting clldutils>=1.7.3\n  Downloading clldutils-3.12.0-py2.py3-none-any.whl (197 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting csvw>=1.5.6\n  Downloading csvw-3.1.1-py2.py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from clldutils>=1.7.3->segments->phonemizer) (6.7.0)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.7/site-packages (from clldutils>=1.7.3->segments->phonemizer) (0.8.10)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from csvw>=1.5.6->segments->phonemizer) (4.6.1)\nCollecting rfc3986<2\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nCollecting isodate\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: uritemplate>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from csvw>=1.5.6->segments->phonemizer) (3.0.1)\nCollecting rdflib\n  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.3/500.3 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.5)\nCollecting language-tags\n  Downloading language_tags-1.1.0-py2.py3-none-any.whl (210 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: babel in /opt/conda/lib/python3.7/site-packages (from csvw>=1.5.6->segments->phonemizer) (2.10.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (5.8.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.18.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (59.8.0)\nInstalling collected packages: rfc3986, language-tags, dlinfo, isodate, rdflib, csvw, clldutils, segments, phonemizer\nSuccessfully installed clldutils-3.12.0 csvw-3.1.1 dlinfo-1.2.1 isodate-0.6.1 language-tags-1.1.0 phonemizer-3.2.1 rdflib-6.2.0 rfc3986-1.5.0 segments-2.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pydub in /opt/conda/lib/python3.7/site-packages (0.25.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.64.0)\nCollecting tqdm\n  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tqdm\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.64.0\n    Uninstalling tqdm-4.64.0:\n      Successfully uninstalled tqdm-4.64.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\nspacy 3.3.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tqdm-4.64.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting gdown\n  Downloading gdown-4.5.3.tar.gz (14 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.6.15.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nBuilding wheels for collected packages: gdown\n  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.3-py3-none-any.whl size=14821 sha256=a663736e56801f9e78d08639968fe093738c20f4acc6541b6dfcf6b73e6544c7\n  Stored in directory: /root/.cache/pip/wheels/94/8d/0b/bdcd83555c3555f91a33f6c2384428d9f163c7d75ab0d272b4\nSuccessfully built gdown\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.5.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting abydos\n  Downloading abydos-0.5.0-py2.py3-none-any.whl (886 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.0/886.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: deprecation in /opt/conda/lib/python3.7/site-packages (from abydos) (2.1.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from abydos) (1.21.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from deprecation->abydos) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->deprecation->abydos) (3.0.9)\nInstalling collected packages: abydos\nSuccessfully installed abydos-0.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!gdown https://drive.google.com/uc?id=16EnTGOzIgSJT69pDAruvbkB35NBJ5R0q\n!unzip \"base_audio (1).zip\" -d base_audio\n!gdown https://drive.google.com/uc?id=1dAJZyLpXHS2y-WCCMXw8m9_j0t1j70Cj\n!unzip ai4talk_tokenizer.zip","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:31:30.569288Z","iopub.execute_input":"2022-10-18T11:31:30.569704Z","iopub.status.idle":"2022-10-18T11:33:23.157968Z","shell.execute_reply.started":"2022-10-18T11:31:30.569658Z","shell.execute_reply":"2022-10-18T11:33:23.156488Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"vQo0tznICf8y"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport re\nfrom tqdm.auto import tqdm\nimport torch\nimport torchaudio\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom abydos import distance\nimport torch.nn as nn\nfrom transformers import AutoModelForCTC, Wav2Vec2Processor, Wav2Vec2FeatureExtractor, Wav2Vec2Tokenizer, Wav2Vec2PhonemeCTCTokenizer, Wav2Vec2Model\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport json\nimport wandb\nwandb.login(key='')\nwandb.init(project=\"ASR\", entity=\"ai_4_talk\")","metadata":{"id":"_KwCfh_gSLVU","execution":{"iopub.status.busy":"2022-10-18T13:12:33.154251Z","iopub.execute_input":"2022-10-18T13:12:33.155172Z","iopub.status.idle":"2022-10-18T13:12:33.725726Z","shell.execute_reply.started":"2022-10-18T13:12:33.155123Z","shell.execute_reply":"2022-10-18T13:12:33.724524Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"class CFG:\n    device = 'cuda'\n    train_batch_size = 2\n    valid_batch_size = 2\n    alpha_ctc = 1\n    num_epoch = 5\n    lr = 5e-5\n    wd = 2e-6\n    eta_min = 0\n    tokenizer_path = 'ai4talk_tokenizer/'\n    checkpoint_path = 'checkpoints/'","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:33:28.174564Z","iopub.execute_input":"2022-10-18T11:33:28.175836Z","iopub.status.idle":"2022-10-18T11:33:28.181470Z","shell.execute_reply.started":"2022-10-18T11:33:28.175781Z","shell.execute_reply":"2022-10-18T11:33:28.180315Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{"id":"ud74HBqtCecY"}},{"cell_type":"code","source":"df = pd.read_csv('base_audio/ars.csv').rename(columns={'new_path': 'audio_path'})\ndf = df.drop_duplicates(subset=['transcription', 'start', 'end', 'fpath']).reset_index(drop=True)","metadata":{"id":"uXTq68XJFE6p","execution":{"iopub.status.busy":"2022-10-18T11:33:28.183362Z","iopub.execute_input":"2022-10-18T11:33:28.184132Z","iopub.status.idle":"2022-10-18T11:33:28.512808Z","shell.execute_reply.started":"2022-10-18T11:33:28.184092Z","shell.execute_reply":"2022-10-18T11:33:28.511782Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df['length_audio'] = df.audio_path.apply(lambda x: torchaudio.load(x)[0].shape[-1])\ndf['length_text'] = df.transcription.apply(lambda x: len(x))","metadata":{"id":"XbRd73pPFPKe","execution":{"iopub.status.busy":"2022-10-18T11:33:28.514152Z","iopub.execute_input":"2022-10-18T11:33:28.515700Z","iopub.status.idle":"2022-10-18T11:33:51.915338Z","shell.execute_reply.started":"2022-10-18T11:33:28.515654Z","shell.execute_reply":"2022-10-18T11:33:51.914280Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = df[(df.length_audio < 100000) & (df.length_audio > 400)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:33:51.916965Z","iopub.execute_input":"2022-10-18T11:33:51.917390Z","iopub.status.idle":"2022-10-18T11:33:51.939127Z","shell.execute_reply.started":"2022-10-18T11:33:51.917348Z","shell.execute_reply":"2022-10-18T11:33:51.937960Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, target, num_splits=5):\n    if num_splits > 1:\n        data.loc[:,'kfold'] = -1\n        X = data.drop(columns=[target])\n        y = data[target]\n        mskf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n        for fold, (trn_, val_) in enumerate(mskf.split(X, y)):\n            data.loc[val_,'kfold'] = fold\n    else:\n        data.loc[:,'kfold'] = 0\n    return data","metadata":{"id":"htjJx0DGFbkB","execution":{"iopub.status.busy":"2022-10-18T11:33:51.940690Z","iopub.execute_input":"2022-10-18T11:33:51.941714Z","iopub.status.idle":"2022-10-18T11:33:51.950462Z","shell.execute_reply.started":"2022-10-18T11:33:51.941668Z","shell.execute_reply":"2022-10-18T11:33:51.949366Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = create_folds(df, 'length_text')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PgcUMP8nG9LK","outputId":"3df27664-7775-4fd0-e7a6-fd4657f90a80","execution":{"iopub.status.busy":"2022-10-18T11:33:51.951939Z","iopub.execute_input":"2022-10-18T11:33:51.952725Z","iopub.status.idle":"2022-10-18T11:33:52.009426Z","shell.execute_reply.started":"2022-10-18T11:33:51.952684Z","shell.execute_reply":"2022-10-18T11:33:52.008329Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  UserWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df, valid_df = df[df.kfold != 0].sort_values(['length_audio'], ignore_index=True), df[df.kfold == 0].sort_values(['length_audio'], ignore_index=True)","metadata":{"id":"_gk5WHIWIhSZ","execution":{"iopub.status.busy":"2022-10-18T11:38:14.581546Z","iopub.execute_input":"2022-10-18T11:38:14.582669Z","iopub.status.idle":"2022-10-18T11:38:14.615249Z","shell.execute_reply.started":"2022-10-18T11:38:14.582628Z","shell.execute_reply":"2022-10-18T11:38:14.614215Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"ij2wVYTrU9FJ"}},{"cell_type":"code","source":"class Tokenizer:\n    def __init__(self, vocab_path):\n        self.vocab = json.load(open(vocab_path))\n        self.token_id = sorted(list(self.vocab.items()), key=lambda x: -len(x[0]))\n        self.id_token = {id_: token for token, id_ in self.vocab.items()}\n    \n    def __call__(self, sentence):\n        for token, id_ in self.token_id:\n            sentence = sentence.replace(token, f' {id_} ')\n        return torch.LongTensor(list(map(int, sentence.split())))\n    \n    def decode(self, sequence):\n        result = ''\n        for id_ in sequence:\n            if self.id_token[id_] != '<pad>':\n                result += self.id_token[id_]\n        return result\n    \n    def batch_decode(self, batch):\n        result = []\n        for sequence in batch:\n            result.append(self.decode(sequence))\n        return result\n    \n    def pad(self, batch):\n        return pad_sequence(batch, batch_first=True, padding_value=self.vocab['<pad>'])\n    \n    @property\n    def vocab_size(self):\n        return len(self.vocab)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:34:39.017877Z","iopub.execute_input":"2022-10-18T11:34:39.018610Z","iopub.status.idle":"2022-10-18T11:34:39.031199Z","shell.execute_reply.started":"2022-10-18T11:34:39.018570Z","shell.execute_reply":"2022-10-18T11:34:39.029939Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class TalkDataset(Dataset):\n    def __init__(self, df, feature_extractor, tokenizer, augmentations=None):\n        super().__init__()\n        self.df = df\n        self.feature_extractor = feature_extractor\n        self.tokenizer = tokenizer\n        self.augmentations = augmentations\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        path = self.df.iloc[idx]['audio_path']\n        text = self.df.iloc[idx]['transcription']\n        waveform, sample_rate = torchaudio.load(path)\n        if self.augmentations:\n            waveform = augmentations(waveform)\n        sample = {}\n        sample['input_values'] = self.feature_extractor(waveform[0], sampling_rate=sample_rate, return_tensors=\"pt\",)['input_values'][0]\n        sample['input_ids'] = self.tokenizer(text)\n        sample['text'] = text.lower()\n        return sample","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:34:39.582631Z","iopub.execute_input":"2022-10-18T11:34:39.583660Z","iopub.status.idle":"2022-10-18T11:34:39.602788Z","shell.execute_reply.started":"2022-10-18T11:34:39.583611Z","shell.execute_reply":"2022-10-18T11:34:39.601707Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class WaveTextCollator:\n    def __init__(self, feature_extractor, tokenizer):\n        self.feature_extractor = feature_extractor\n        self.tokenizer = tokenizer\n        \n    def __call__(self, batch):\n        input_values = [{'input_values': feature['input_values']} for feature in batch]\n        input_values = self.feature_extractor.pad(\n            input_values,\n            padding=True,\n            return_tensors=\"pt\",\n        )\n        input_ids = [feature['input_ids'] for feature in batch]\n        text_lens = torch.LongTensor([text.size(0) for text in input_ids])\n        input_ids = self.tokenizer.pad(\n            input_ids,\n        )\n        texts = [feature['text'] for feature in batch]\n        \n        return input_values, texts, input_ids, text_lens","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:34:40.151796Z","iopub.execute_input":"2022-10-18T11:34:40.152935Z","iopub.status.idle":"2022-10-18T11:34:40.165181Z","shell.execute_reply.started":"2022-10-18T11:34:40.152896Z","shell.execute_reply":"2022-10-18T11:34:40.164184Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class AverageMeter:\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:34:40.793266Z","iopub.execute_input":"2022-10-18T11:34:40.794285Z","iopub.status.idle":"2022-10-18T11:34:40.801138Z","shell.execute_reply.started":"2022-10-18T11:34:40.794238Z","shell.execute_reply":"2022-10-18T11:34:40.800006Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class CTCrossEntropyLoss:\n    def __init__(self, alpha):\n        self.ctc_criterion = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n        self.ce_criterion = nn.CrossEntropyLoss(ignore_index=0)\n        self.alpha = alpha\n        \n    def __call__(self, output, enc_pad_texts, output_lenghts, text_lens):\n        log_probs = nn.functional.log_softmax(output, dim=-1, dtype=torch.float32).transpose(0, 1)\n        ctc_loss = self.ctc_criterion(log_probs, enc_pad_texts, output_lenghts, text_lens)\n        \n        #ce_loss = self.ce_criterion(output.view(output.size(0), -1), enc_pad_texts.view(-1))\n        return self.alpha * ctc_loss","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:34:41.503753Z","iopub.execute_input":"2022-10-18T11:34:41.504693Z","iopub.status.idle":"2022-10-18T11:34:41.512288Z","shell.execute_reply.started":"2022-10-18T11:34:41.504639Z","shell.execute_reply":"2022-10-18T11:34:41.511013Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def metric(y_true, y_pred):\n    phonetic = distance.PhoneticEditDistance()\n    return sum(phonetic.dist(t, p) for t, p in zip(y_true, y_pred)) / len(y_true)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:34:43.007487Z","iopub.execute_input":"2022-10-18T11:34:43.007864Z","iopub.status.idle":"2022-10-18T11:34:43.013355Z","shell.execute_reply.started":"2022-10-18T11:34:43.007830Z","shell.execute_reply":"2022-10-18T11:34:43.012079Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, loader, criterion, optimizer, scheduler):\n    loss_avg = AverageMeter()\n    model.train()\n    for input_values, texts, input_ids, text_lens in tqdm(loader):\n        optimizer.zero_grad()\n        output = model(input_values['input_values'].to(CFG.device), input_values['attention_mask'].to(CFG.device))\n        output_lenghts = torch.full(\n            size=(output.size(0),),\n            fill_value=output.size(1),\n            dtype=torch.long\n        )\n        loss = criterion(output, input_ids.to(CFG.device), output_lenghts, text_lens)\n        loss_avg.update(loss.item(), len(texts))\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n    return loss_avg.avg","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:38:18.879113Z","iopub.execute_input":"2022-10-18T11:38:18.880092Z","iopub.status.idle":"2022-10-18T11:38:18.892213Z","shell.execute_reply.started":"2022-10-18T11:38:18.880037Z","shell.execute_reply":"2022-10-18T11:38:18.891136Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def valid_epoch(model, loader, criterion):\n    model.eval()\n    loss_avg = AverageMeter()\n    metric_avg = AverageMeter()\n    with torch.no_grad():\n        for input_values, texts, input_ids, text_lens in tqdm(loader):\n            output = model(input_values['input_values'].to(CFG.device), input_values['attention_mask'].to(CFG.device))\n            output_lenghts = torch.full(\n                size=(output.size(0),),\n                fill_value=output.size(1),\n                dtype=torch.long\n            )\n            loss = criterion(output, input_ids.to(CFG.device), output_lenghts, text_lens, )\n            loss_avg.update(loss.item(), len(texts))\n            pred_ids = torch.argmax(output.detach().cpu(), dim=-1).numpy()\n            pred_str = tokenizer.batch_decode(pred_ids)\n            try:\n                metric_avg.update(metric(texts, pred_str), len(texts))\n            except:\n                pass\n        print(texts, pred_str)\n    return loss_avg.avg, metric_avg.avg","metadata":{"execution":{"iopub.status.busy":"2022-10-18T12:53:19.585859Z","iopub.execute_input":"2022-10-18T12:53:19.586291Z","iopub.status.idle":"2022-10-18T12:53:19.596700Z","shell.execute_reply.started":"2022-10-18T12:53:19.586258Z","shell.execute_reply":"2022-10-18T12:53:19.595421Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def fit(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epoch, checkpoint_path):\n    for epoch in tqdm(range(num_epoch)):\n        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler)\n        valid_loss, valid_ped = valid_epoch(model, valid_loader, criterion)\n        wandb.log({'Epoch': epoch+1, 'Train loss': train_loss, 'Valid loss': valid_loss, 'Valid PED': valid_ped, 'LR': scheduler.get_last_lr()[0]})\n        torch.save({'model': model.state_dict(), checkpoint_path + f'epoch{epoch+1}_ped{valid_ped}.pt'})","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:38:20.379129Z","iopub.execute_input":"2022-10-18T11:38:20.379552Z","iopub.status.idle":"2022-10-18T11:38:20.387103Z","shell.execute_reply.started":"2022-10-18T11:38:20.379509Z","shell.execute_reply":"2022-10-18T11:38:20.384875Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Wav2VecCTC(nn.Module):\n    def __init__(self, vocab_size, dropout=0.0):\n        super().__init__()\n        self.encoder = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")\n        self.encoder.config.mask_time_length = 1\n        self.dropout = nn.Dropout(dropout)\n        output_hidden_size = self.encoder.config.hidden_size\n        self.lm_head = nn.Linear(output_hidden_size, vocab_size)\n        \n    def forward(self, input_values, attention_mask):\n        outputs = self.encoder(\n            input_values,\n            attention_mask=attention_mask,\n        )\n\n        hidden_states = outputs[0]\n        hidden_states = self.dropout(hidden_states)\n\n        logits = self.lm_head(hidden_states)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:38:21.552251Z","iopub.execute_input":"2022-10-18T11:38:21.555085Z","iopub.status.idle":"2022-10-18T11:38:21.562952Z","shell.execute_reply.started":"2022-10-18T11:38:21.555033Z","shell.execute_reply":"2022-10-18T11:38:21.561480Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(CFG.tokenizer_path + 'vocab.json')\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")\nmodel = Wav2VecCTC(tokenizer.vocab_size).to(CFG.device)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:38:22.275352Z","iopub.execute_input":"2022-10-18T11:38:22.275765Z","iopub.status.idle":"2022-10-18T11:38:26.852023Z","shell.execute_reply.started":"2022-10-18T11:38:22.275732Z","shell.execute_reply":"2022-10-18T11:38:26.850855Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-xlsr-53-espeak-cv-ft were not used when initializing Wav2Vec2Model: ['lm_head.bias', 'lm_head.weight']\n- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = TalkDataset(train_df, feature_extractor, tokenizer)\nvalid_dataset = TalkDataset(valid_df, feature_extractor, tokenizer)\ncollator = WaveTextCollator(feature_extractor, tokenizer)\ntrain_loader = DataLoader(train_dataset, batch_size=CFG.train_batch_size, shuffle=False, collate_fn=collator, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_batch_size, shuffle=False, collate_fn=collator, pin_memory=True)\ncriterion = CTCrossEntropyLoss(CFG.alpha_ctc)\noptimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\nscheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader) * CFG.num_epoch, eta_min=CFG.eta_min)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:38:35.685096Z","iopub.execute_input":"2022-10-18T11:38:35.685501Z","iopub.status.idle":"2022-10-18T11:38:35.698584Z","shell.execute_reply.started":"2022-10-18T11:38:35.685467Z","shell.execute_reply":"2022-10-18T11:38:35.697421Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"fit(model, train_loader, valid_loader, criterion, optimizer, scheduler, CFG.num_epoch, CFG.checkpoint_path)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T11:38:38.957280Z","iopub.execute_input":"2022-10-18T11:38:38.957979Z","iopub.status.idle":"2022-10-18T12:44:36.533571Z","shell.execute_reply.started":"2022-10-18T11:38:38.957940Z","shell.execute_reply":"2022-10-18T12:44:36.531102Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"383d129a80ec43b083399334e42180c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/22812 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7913b0d403174f4085cc3a4083377e78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5704 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e9d39b46c354d968372efae4532079e"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2926273831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_17/626266151.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Valid loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Valid PED:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LR:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/1361158541.py\u001b[0m in \u001b[0;36mvalid_epoch\u001b[0;34m(model, loader, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mpred_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpred_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmetric_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/2846972752.py\u001b[0m in \u001b[0;36mmetric\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mphonetic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhoneticEditDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphonetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_17/2846972752.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mphonetic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhoneticEditDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphonetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/abydos/distance/_phonetic_edit_distance.py\u001b[0m in \u001b[0;36mdist\u001b[0;34m(self, src, tar)\u001b[0m\n\u001b[1;32m    286\u001b[0m         )\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormalize_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/abydos/distance/_phonetic_edit_distance.py\u001b[0m in \u001b[0;36mdist_abs\u001b[0;34m(self, src, tar)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdel_cost\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0md_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alignment_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0md_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/abydos/distance/_phonetic_edit_distance.py\u001b[0m in \u001b[0;36m_alignment_matrix\u001b[0;34m(self, src, tar, backtrace)\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0msub_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcmp_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                         \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     ),  # sub/==\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"phonetic = distance.PhoneticEditDistance()\nphonetic.dist('pnt͡ʃ', 'ant͡ʃ')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T12:50:52.131091Z","iopub.execute_input":"2022-10-18T12:50:52.131471Z","iopub.status.idle":"2022-10-18T12:50:52.159752Z","shell.execute_reply.started":"2022-10-18T12:50:52.131432Z","shell.execute_reply":"2022-10-18T12:50:52.158169Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/4092087995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mphonetic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhoneticEditDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mphonetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nt͡ʃ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ant͡ʃ'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/abydos/distance/_phonetic_edit_distance.py\u001b[0m in \u001b[0;36mdist\u001b[0;34m(self, src, tar)\u001b[0m\n\u001b[1;32m    286\u001b[0m         )\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormalize_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/abydos/distance/_phonetic_edit_distance.py\u001b[0m in \u001b[0;36mdist_abs\u001b[0;34m(self, src, tar)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdel_cost\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0md_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alignment_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0md_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/abydos/distance/_phonetic_edit_distance.py\u001b[0m in \u001b[0;36m_alignment_matrix\u001b[0;34m(self, src, tar, backtrace)\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0msub_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcmp_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                         \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     ),  # sub/==\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"'ant͡ʃ'[3]","metadata":{"execution":{"iopub.status.busy":"2022-10-18T14:08:49.213515Z","iopub.execute_input":"2022-10-18T14:08:49.213851Z","iopub.status.idle":"2022-10-18T14:08:49.219910Z","shell.execute_reply.started":"2022-10-18T14:08:49.213824Z","shell.execute_reply":"2022-10-18T14:08:49.218992Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'͡'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}